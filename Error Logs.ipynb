{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Error Logs.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPCjHS7+Y7P+eBbW8E86WNX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OQ3K8aSgvPr5"},"source":["# Point 1: Train model on custom dataset"]},{"cell_type":"markdown","metadata":{"id":"vJjqPy8aMTBV"},"source":["###Experiment 0: View the Dataset\n","* Result: Dataset contains 62 classes, with 0-9 digits a-z and A-Z.\n","* It is similar to MNIST and EMNIST except that the images are negative(Background white and forground black)\n","* Also the region of interest is not in centre of each image\n","* There are exactly 40 images per class with size 900x1200, definitely less in number compared to MNIST"]},{"cell_type":"markdown","metadata":{"id":"EHDGU9WpvatM"},"source":["### Experiment 1: Load all the images in the dataset directly into ram\n","- **Result**: Sesion crash\n","* Since the each image is of size 900x1200, all the images could not be loaded into ram\n","* And also the amount of information in images information is not very much so, resizing the image to a smaller size should help\n","* **Conclusion** Resize each image to 64x64\n"]},{"cell_type":"markdown","metadata":{"id":"JjUEGV5cyBcE"},"source":["### Experiment 2: Resize images, convert to grayscale and train LeNet architecture as baseline\n","- **Result**: An accuracy of 83% on train set and 52% on test set\n","* Lenet5 is a very simple model with only 2 convlayers and average pooling\n","* There is high bias and high variance, as evident from above numbers\n","* The images in dataset have the object of interest as black and background as black. This is opposite to MNIST. Neural Netowrks do not generalize to negative imageas according to [this paper](https://arxiv.org/abs/1703.06857)\n","* Hence we invert thr pixels using cv2.bitwise not\n","* Further on images where the region of interest is white in color, max pooling works better than average pooling.\n","* **Conclusion** Increase model complexity, make it more deep, invert pixels and use maxpooling instead of average poolling\n"]},{"cell_type":"markdown","metadata":{"id":"ftkQk5tryBmX"},"source":["### Experiment 3: Add more layers to CNN and a couple of maxpooling layers \n","- **Result**: Train set accuracy of 98.73% and validation set accuracy of 64.78%\n","* An additional Learning Rate decay sh also added, with lr decresing on plateaus of validation loss \n","* Validation set accuracy improves, significantly, however the model overfits\n","* Hence adding dropout and batch regularization after each layer should help.\n","* **Conclusion** Regularize netowork\n"]},{"cell_type":"markdown","metadata":{"id":"VQM_jXxkyBvl"},"source":["### Experiment 4: Regularize the network by adding dropout of 0.25 and batchNorm after every 2 conv layer and after FCL\n","- **Result**: Train set accuracy of 94.73% and validation set accuracy 76.78%\n","* The results have improved significantly with less overfitting and better generalization to validation set\n","* Making more variations in this architecture, does not imporve the results much\n","* **Conclusion** Try other advanced archtecture like resnetv2, resnetv2 and MobileNet\n"]},{"cell_type":"markdown","metadata":{"id":"usgOj0wJKdne"},"source":["### Experiment 5: Try advanced archtecture like ResNet, ReSnetV2, with no pretrained weight\n","- **Result**: Resnetv2 performed the best with Train set accuracy of 96.44% and validation set accuracy 80%\n","* The results have improved significantly with less overfitting and better generalization to validation set\n","* Advanced architectures outperform the LeNet variant\n","* **Conclusion** See if further preprocessing helps, some ideas:\n","    * Center the region of interest in the image as mentiones in Exp 0\n","    * Perform Gaussian blur\n"]},{"cell_type":"markdown","metadata":{"id":"4lUgmVUiNJBw"},"source":["### Experiment 6: Modifying input images further: Centering the image, bringing ROI in centre.\n","**Result**: \n","* For Custom LeNet Train set accuracy: 98% and Vadidation set accuracy of 83.01% \n","\n","* For ResNetv2 Train set accuracy: 96% and Vadidation set accuracy of 84.54% \n","\n","* Results have significantly improved"]},{"cell_type":"markdown","metadata":{"id":"JZEsogCRbQoP"},"source":["### Experiment 7: Applying Gaussian Blue (3x3) along with ROI in centre.\n","**Result**: \n","* For Custom LeNet Train set accuracy: 98% and Vadidation set accuracy of 84.54% \n","\n","* For ResNetv2 Train set accuracy: 95.77% and Vadidation set accuracy of 87.6% \n","\n","* Results have significantly improved"]},{"cell_type":"code","metadata":{"id":"btqlTWgyGpnM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZOt9FQxyZfk"},"source":["# Point 2: Train model on custom dataset 0-9 digits and then train on MNIST"]},{"cell_type":"markdown","metadata":{"id":"eYxuEt4vyefv"},"source":["### Experiment 1: We use Resnet50V2 and Custom CNN (best perfroming for 62 classes) and train it on 0-9 digits with the same preprocessing steps as shown earlier\n","- **Result**: Custom CNN training accuracy: 100%, validation accuracy 97.5%\n","- Resnet50v2-training accuracy: 99.6%, validation accuracy 95.5%\n","* Lenet Performs sufficiently good, so we continue with this architecture further\n","* **Conclusion** Use the above trained Lenet and start with MNIST traning and testing\n","- To maximize effectiveness of pre-training check accuracy of this netowrk on MNIST test set.\n"]},{"cell_type":"markdown","metadata":{"id":"9i5L93ccyefw"},"source":["### Experiment 2: Preprocessing MNIST by resizing to MNIST iamges to ``64x64``\n","- **Result**: An accuracy of 26.55% on test MNIST\n","- Since it is greater than 10% (random probability), it means that the model has learnt something.\n","- To improve upon it, we should make the MNIST dataset more like the custom dataset.\n","- Region of interest should be in focus.\n","* **Conclusion** Crop MNiST to bring digits in focus"]},{"cell_type":"markdown","metadata":{"id":"Wul-9MvBhKrf"},"source":["### Experiment 3: Preprocessing MNIST by resizing to MNIST iamges to ``64x64`` and bringing ROI in focus\n","- **Result**: An accuracy of 73.49% on test MNIST\n","- Images have been preprocessed enough time to train \n","* **Conclusion** MNIST images have been preprocessed"]},{"cell_type":"markdown","metadata":{"id":"rRtRRTH-hKxN"},"source":["### Experiment 4: Training MNIST on pretrained network and on randomnly intialized network\n","- **Result**: An accuracy of 26.55% on test MNIST\n","* It can be seen that pretrained network starts off with higher accuracy and lower loss compared to randomly initialized network.\n","* Since pretrained network has already learnt basic digits features, it is easier for it to be trained on MNIST\n","* However by 12-15th epoch the both networks converge to same value\n","**Conclusion** Pretrained network converge faster than randomly initialized network"]},{"cell_type":"markdown","metadata":{"id":"52Wh4DVqMLpC"},"source":["#Point 3: Train model on dataset with wrong labels"]},{"cell_type":"markdown","metadata":{"id":"GZ1oq1lGMTET"},"source":["### Experiment 1: Analyse the dataset\n","- **Result**: Dataset has a pattern\n","- Initially it seems that there is not pattern in the data. But there is.\n","- images in a folder correspond to those images that are not that label, a complement\n","- Hence making netowrk with the learning objective to identify classes that the image does not belong to should help\n","**Conclusion**  Train a network which will ouput a probability vector of P of 10 dimensoions, where P[i] corresponds to the probability of the image not being the ith digit.\n","Hence for inference we will take the minimum output probability. For testing we will test it on MNIST dataset"]},{"cell_type":"markdown","metadata":{"id":"O4Yaz-LRR6uX"},"source":["### Experiment 2: Build the network and test on MNIST test set\n","- **Result**: The network works and gives an accuracy of 95% (due to random initialization sometimes 96%)\n","- The model is trained with categorical cross entropy and a softmax output\n","- Other intresting variation tried was binarycrossentropy and sigmoid output which enables the network to be outputs which are independent to each other. Something similar is done in Multi-label classification\n","- Future work includes working with the above variation"]},{"cell_type":"markdown","metadata":{"id":"FMBph26gT7MH"},"source":[""]},{"cell_type":"code","metadata":{"id":"PPuBhviWNB2Q"},"source":[""],"execution_count":null,"outputs":[]}]}